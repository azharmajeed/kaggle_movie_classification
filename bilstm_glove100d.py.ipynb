{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import keras\n",
    "import keras.preprocessing.text\n",
    "import nltk\n",
    "from keras.preprocessing import sequence\n",
    "from keras.models import Sequential, model_from_json, load_model\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.utils.np_utils import to_categorical\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.layers.wrappers import Bidirectional\n",
    "from keras import optimizers\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.externals import joblib\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movies_data=pd.read_csv('movies_metadata.csv')\n",
    "df=movies_data[['original_title','overview','genres','original_language']].loc[movies_data['original_language']=='en']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_genres(x):\n",
    "    genres=[]\n",
    "    for i in eval(x):\n",
    "        genres.append(i['name'])\n",
    "    return genres\n",
    "\n",
    "df['genre']=df['genres'].apply(lambda x : strip_genres(x))\n",
    "df.drop(['genres','original_language'],axis=1,inplace=True)\n",
    "\n",
    "# function for text cleaning \n",
    "def clean_text(text):\n",
    "    # remove everything except alphabets \n",
    "    text = re.sub(\"[^a-zA-Z]\",\" \",text) \n",
    "    # remove whitespaces \n",
    "    text = ' '.join(text.split()) \n",
    "    # convert text to lowercase \n",
    "    text = text.lower() \n",
    "    \n",
    "    return text\n",
    "df['overview'] = df['overview'].apply(lambda x: clean_text(str(x)))\n",
    "\n",
    "\n",
    "# function to remove stopwords\n",
    "def remove_stopwords(text):\n",
    "    no_stopword_text = [w for w in text.split() if not w in stop_words]\n",
    "    return ' '.join(no_stopword_text)\n",
    "\n",
    "df['overview'] = df['overview'].apply(lambda x: remove_stopwords(x))\n",
    "\n",
    "#tokenize the words with their indices to pass to the model\n",
    "tk = keras.preprocessing.text.Tokenizer(num_words=None, filters='!\"#$%&()*+,-./:;<=>?@[\\\\]^_`{|}~\\t\\n', lower=True, split=\" \")\n",
    "tk.fit_on_texts(df['overview'])\n",
    "x_train = tk.texts_to_sequences(df['overview'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_index = tk.word_index  # index of unique words\n",
    "print('Found %s unique tokens.' % len(word_index))\n",
    "\n",
    "mlb = MultiLabelBinarizer()\n",
    "y_train  = mlb.fit_transform(df['genre'])\n",
    "\n",
    "\n",
    "\n",
    "max_len = 64     #length of sequence\n",
    "batch_size = 32\n",
    "epochs = 64\n",
    "max_features = len(word_index) + 1   # (number of words in the vocabulary) + 1\n",
    "\n",
    "x_train = sequence.pad_sequences(x_train, maxlen=max_len, padding='pre')\n",
    "\n",
    "xtrain, xtest, ytrain, ytest = train_test_split(x_train, y_train, test_size=0.2, random_state=42)\n",
    "\n",
    "print('x_train shape:', xtrain.shape)\n",
    "print('x_test shape:', xtest.shape)\n",
    "\n",
    "print('y_train shape:', ytrain.shape)\n",
    "print('y_test shape:', ytest.shape)\n",
    "label_num = len(y_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting the glove embeddingsm\n",
    "embeddings_index = {}\n",
    "f = open('glove.6B.100d.txt',encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    emb_weights = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = emb_weights\n",
    "f.close()\n",
    "print('Found %s word vectors.' % len(embeddings_index))\n",
    "\n",
    "#defining the learnt matrix to pass to the embedding the layer weights\n",
    "embedding_matrix = np.zeros((max_features, 100))\n",
    "\n",
    "#the words not in the embedding matrix will be zeros\n",
    "for word, i in word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "\n",
    "max_len = 64       #length of sequence\n",
    "batch_size = 32\n",
    "epochs = 64\n",
    "\n",
    "#initating the weights of the embedding layer\n",
    "embedding_layer = Embedding(input_dim = max_features,\n",
    "                            output_dim = 100,\n",
    "                            weights=[embedding_matrix],\n",
    "                            mask_zero = True,\n",
    "                            input_length = max_len,\n",
    "                            trainable = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# building the model and compiling it\n",
    "\n",
    "model = Sequential()\n",
    "model.add(embedding_layer)\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(LSTM(64,return_sequences=True)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Bidirectional(LSTM(64)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(label_num, activation = 'sigmoid'))\n",
    "\n",
    "print(model.summary())\n",
    "\n",
    "#rmsprop = optimizers.RMSprop(lr = 0.01, decay = 0.0001)\n",
    "model.compile(optimizer ='adam', loss = 'binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n",
    "# fitting the data on the model and saving the weights obtained\n",
    "\n",
    "model.fit(xtrain, ytrain, epochs=epochs, batch_size= batch_size,validation_split=0.2,verbose=1,validation_data=[xtest, ytest])\n",
    "\n",
    "#model.save_weights('my_model_weights.h5')\n",
    "model.save('bi-lstm-glove.h5')\n",
    "\n",
    "\n",
    "output = model.predict(xtest)\n",
    "output = np.array(out)\n",
    "\n",
    "y_pred = np.zeros(out.shape)\n",
    "#setting a threshold of 0.5\n",
    "y_pred[output>0.5]=1\n",
    "y_pred = np.array(y_pred)\n",
    "\n",
    "print(mlb.inverse_transform(y_pred)[0])\n",
    "\n",
    "f1 = metrics.f1_score(ytest,y_pred, average = 'micro')\n",
    "print(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''# Creating a reverse dictionary\n",
    "reverse_word_map = dict(map(reversed, tk.word_index.items()))\n",
    "# Function takes a tokenized sentence and returns the words\n",
    "def sequence_to_text(list_of_indices):\n",
    "    # Looking up words in dictionary\n",
    "    words = [reverse_word_map.get(letter) for letter in list_of_indices]\n",
    "    return(words)\n",
    "# Creating texts \n",
    "my_texts = list(map(sequence_to_text, xtest))'''\n",
    "\n",
    "\n",
    "#printing the first ten test results\n",
    "df_xtest1=df_xtest.copy().reset_index()\n",
    "for i in range(10):\n",
    "    print('Title:', df_xtest1.loc[i,'original_title'])\n",
    "    print('Actual Genres:',mlb.inverse_transform(ytest)[i])\n",
    "    print('Predicted Genres:',mlb.inverse_transform(y_pred)[i])\n",
    "    print('-----------')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
